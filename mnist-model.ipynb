{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-18T13:00:58.918046Z",
     "iopub.status.busy": "2024-02-18T13:00:58.917546Z",
     "iopub.status.idle": "2024-02-18T13:01:14.902963Z",
     "shell.execute_reply": "2024-02-18T13:01:14.901346Z",
     "shell.execute_reply.started": "2024-02-18T13:00:58.917986Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-18 13:27:28.236075: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/phil/MultiNest/lib/:\n",
      "2024-02-18 13:27:28.236146: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T13:01:14.905671Z",
     "iopub.status.busy": "2024-02-18T13:01:14.905046Z",
     "iopub.status.idle": "2024-02-18T13:01:19.304675Z",
     "shell.execute_reply": "2024-02-18T13:01:19.303586Z",
     "shell.execute_reply.started": "2024-02-18T13:01:14.905639Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the MNIST data-set\n",
    "# This data has alreay been converted to CSV and split into test and training sets, \n",
    "# to get more control over this we we will merge these sets then split them again later down the line\n",
    "mnist_a= pd.read_csv('mnist/mnist_train.csv')\n",
    "mnist_b = pd.read_csv('mnist/mnist_test.csv')\n",
    "mnist = pd.concat([mnist_a, mnist_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T13:01:19.307008Z",
     "iopub.status.busy": "2024-02-18T13:01:19.306527Z",
     "iopub.status.idle": "2024-02-18T13:01:19.338874Z",
     "shell.execute_reply": "2024-02-18T13:01:19.337776Z",
     "shell.execute_reply.started": "2024-02-18T13:01:19.306971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick look at the data\n",
    "mnist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T13:01:19.344232Z",
     "iopub.status.busy": "2024-02-18T13:01:19.343275Z",
     "iopub.status.idle": "2024-02-18T13:01:20.772966Z",
     "shell.execute_reply": "2024-02-18T13:01:20.772065Z",
     "shell.execute_reply.started": "2024-02-18T13:01:19.344197Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separate labels and one-hot-encode them\n",
    "X = mnist\n",
    "y = X.pop('label')\n",
    "y =pd.get_dummies(y)\n",
    "\n",
    "y.head()\n",
    "\n",
    "#Separate out training and validation data\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "    train_test_split(X, y, stratify=y, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T13:06:37.310010Z",
     "iopub.status.busy": "2024-02-18T13:06:37.309619Z",
     "iopub.status.idle": "2024-02-18T13:06:37.434330Z",
     "shell.execute_reply": "2024-02-18T13:06:37.433213Z",
     "shell.execute_reply.started": "2024-02-18T13:06:37.309966Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-18 13:27:50.408881: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/phil/MultiNest/lib/:\n",
      "2024-02-18 13:27:50.408943: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-02-18 13:27:50.408985: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ULTIMA): /proc/driver/nvidia/version does not exist\n",
      "2024-02-18 13:27:50.409492: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Set up the model\n",
    "input_shape = [X_train.shape[1]]\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.BatchNormalization(input_shape=input_shape),\n",
    "    \n",
    "    layers.Dense(units=256, activation='relu', input_shape=input_shape),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.Dense(units=128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.Dense(units=10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T13:08:56.903619Z",
     "iopub.status.busy": "2024-02-18T13:08:56.903207Z",
     "iopub.status.idle": "2024-02-18T13:08:56.919323Z",
     "shell.execute_reply": "2024-02-18T13:08:56.917629Z",
     "shell.execute_reply.started": "2024-02-18T13:08:56.903584Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['acc'],\n",
    ")\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta = 0.0001,\n",
    "    patience = 25,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T13:09:00.227425Z",
     "iopub.status.busy": "2024-02-18T13:09:00.227072Z",
     "iopub.status.idle": "2024-02-18T13:12:30.774195Z",
     "shell.execute_reply": "2024-02-18T13:12:30.772209Z",
     "shell.execute_reply.started": "2024-02-18T13:09:00.227397Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-18 13:28:12.164429: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3364 - acc: 0.8966 - val_loss: 0.2571 - val_acc: 0.9543\n",
      "Epoch 2/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.1759 - acc: 0.9458 - val_loss: 0.2234 - val_acc: 0.9632\n",
      "Epoch 3/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.1375 - acc: 0.9563 - val_loss: 0.3239 - val_acc: 0.9675\n",
      "Epoch 4/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.1175 - acc: 0.9629 - val_loss: 0.2330 - val_acc: 0.9710\n",
      "Epoch 5/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.1054 - acc: 0.9664 - val_loss: 0.3854 - val_acc: 0.9708\n",
      "Epoch 6/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0937 - acc: 0.9706 - val_loss: 0.2726 - val_acc: 0.9728\n",
      "Epoch 7/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0831 - acc: 0.9730 - val_loss: 0.4126 - val_acc: 0.9738\n",
      "Epoch 8/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0799 - acc: 0.9739 - val_loss: 0.3015 - val_acc: 0.9746\n",
      "Epoch 9/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0739 - acc: 0.9757 - val_loss: 0.3652 - val_acc: 0.9761\n",
      "Epoch 10/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0713 - acc: 0.9767 - val_loss: 0.2404 - val_acc: 0.9757\n",
      "Epoch 11/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0623 - acc: 0.9796 - val_loss: 0.2668 - val_acc: 0.9763\n",
      "Epoch 12/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0628 - acc: 0.9789 - val_loss: 0.1937 - val_acc: 0.9761\n",
      "Epoch 13/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0584 - acc: 0.9810 - val_loss: 0.3412 - val_acc: 0.9783\n",
      "Epoch 14/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0574 - acc: 0.9809 - val_loss: 0.3184 - val_acc: 0.9770\n",
      "Epoch 15/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0523 - acc: 0.9828 - val_loss: 0.2697 - val_acc: 0.9776\n",
      "Epoch 16/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0558 - acc: 0.9816 - val_loss: 0.3314 - val_acc: 0.9775\n",
      "Epoch 17/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0499 - acc: 0.9835 - val_loss: 0.4074 - val_acc: 0.9758\n",
      "Epoch 18/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0475 - acc: 0.9850 - val_loss: 0.3031 - val_acc: 0.9766\n",
      "Epoch 19/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0461 - acc: 0.9850 - val_loss: 0.3541 - val_acc: 0.9765\n",
      "Epoch 20/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0458 - acc: 0.9851 - val_loss: 0.3012 - val_acc: 0.9778\n",
      "Epoch 21/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0441 - acc: 0.9854 - val_loss: 0.2765 - val_acc: 0.9781\n",
      "Epoch 22/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0403 - acc: 0.9865 - val_loss: 0.3978 - val_acc: 0.9790\n",
      "Epoch 23/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0428 - acc: 0.9856 - val_loss: 0.3716 - val_acc: 0.9793\n",
      "Epoch 24/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0415 - acc: 0.9865 - val_loss: 0.4491 - val_acc: 0.9791\n",
      "Epoch 25/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0382 - acc: 0.9879 - val_loss: 0.3014 - val_acc: 0.9771\n",
      "Epoch 26/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0366 - acc: 0.9878 - val_loss: 0.3099 - val_acc: 0.9778\n",
      "Epoch 27/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0400 - acc: 0.9865 - val_loss: 0.5195 - val_acc: 0.9783\n",
      "Epoch 28/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0369 - acc: 0.9876 - val_loss: 0.3451 - val_acc: 0.9798\n",
      "Epoch 29/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0352 - acc: 0.9890 - val_loss: 0.3332 - val_acc: 0.9801\n",
      "Epoch 30/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0336 - acc: 0.9888 - val_loss: 0.3801 - val_acc: 0.9790\n",
      "Epoch 31/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0372 - acc: 0.9882 - val_loss: 0.3268 - val_acc: 0.9778\n",
      "Epoch 32/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0315 - acc: 0.9890 - val_loss: 0.5403 - val_acc: 0.9799\n",
      "Epoch 33/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0322 - acc: 0.9893 - val_loss: 0.3355 - val_acc: 0.9786\n",
      "Epoch 34/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0343 - acc: 0.9884 - val_loss: 0.3015 - val_acc: 0.9784\n",
      "Epoch 35/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0304 - acc: 0.9892 - val_loss: 0.3850 - val_acc: 0.9783\n",
      "Epoch 36/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0305 - acc: 0.9898 - val_loss: 0.4253 - val_acc: 0.9785\n",
      "Epoch 37/50\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0293 - acc: 0.9896 - val_loss: 0.3198 - val_acc: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Accuracy'}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=50, \n",
    "    batch_size=50,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\n",
    "history_df.loc[:, ['acc', 'val_acc']].plot(title=\"Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 27352,
     "sourceId": 34877,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
